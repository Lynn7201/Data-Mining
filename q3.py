# -*- coding: utf-8 -*-
"""Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wXjd30lmIHiB9lmJno4jXpiCh0uDE05M

### QUESTION 3: Python Programming [10 marks]
Study “Open Data on COVID-19 in Malaysia” by the Ministry of Health (MOH), Malaysia
via https://github.com/MoH-Malaysia/covid19-public . Use only
datasets from the categories “Cases and Testing”, “Healthcare”, “Deaths”, and “Static
data” for this assignment.

Answer the following questions and prepare your findings using the “Streamlit” package.
Upload it Heroku.com. Each analysis must have at least one chart and a short paragraph
explaining your findings.
"""

import pandas as pd
import seaborn as sns
from sklearn import svm
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
import statistics as stat
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from collections import Counter
from sklearn import metrics
from sklearn.metrics import mean_absolute_error as mae
from sklearn.metrics import classification_report
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime

from pandas import read_csv
from pandas.plotting import scatter_matrix
from matplotlib import pyplot
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from collections import Counter

# Loading data from local drive

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

"""#### (i) 
Discuss the exploratory data analysis steps you have conducted including detection of outliers and missing values? 
<font color="red"> (2m) </font>
"""

lim_cases_state_dataset = pd.read_csv ("cases_state.csv")
print (lim_cases_state_dataset)

lim_cases_state_df = pd.DataFrame(lim_cases_state_dataset)

#dropna() function used for pre-processing dataset. Checking for empty
lim_cases_state_df.dropna()

#isnull() function used to check for missing value in dataset. The displayed data below shown that there are no missing data
lim_cases_state_df.isnull().sum()

#data Distribution
# visualize the variable in dataset
g = sns.countplot(lim_cases_state_df['state'].head(100))
plt.show()

#Class Distribution
# visualize the variable in dataset
g = sns.countplot(lim_cases_state_df['date'].head(100))
plt.show()

# data distribution
print(lim_cases_state_df.groupby('state').size())

"""#### (ii) 
What are the states that exhibit strong correlation with (i) Pahang, and (ii) Johor? <font color="red"> (2m) </font>
"""

# To find the correlation among states
# the columns using pearson method
lim_cases_state_df.corr(method ='pearson')

# Based on table above, Sarawak state has strong correlation with Pahang.
# Melaka state has strong correlation with Johor

"""#### (iii) 
What are the strong features/indicators to daily cases for (i) Pahang, (ii) Kedah,(iii) Johor, and (iv) Selangor? <font color="red"> (3m) </font>

[Note: you must use at least 2 methods to justify your findings]

#### (iv) 

Comparing regression and classification models, what model performs well in predicting the daily cases for (i) Pahang, (ii) Kedah, (iii) Johor, and (iv) Selangor? <font color="red"> (3m) </font>

Requirements:
1. Use TWO(2) regression models and TWO(2) classification models
2. Use appropriate evaluation metrics.
"""

# Using TWO(2) regression models: Logistic Regression and Super vector machine (SVM)algorithm.
# TWO(2) classification models used Decision tree model and Naive bayes model

#1. Logistic Regression
x_data = lim_cases_state_df.drop(['date', 'state'],axis = 1)

x_data

states = lim_cases_state_df['state']
states

X=x_data
y=states

#splitting dataset into 20% / 80% 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Logistic Regression Algorithm

clf_log = LogisticRegression()

cross_val_score(clf_log,X,y)

clf_log.fit(X_train,y_train)

clf1=clf_log.fit(X,y)
y_pred = clf1.fit(X_train, y_train).predict(X_test)

accuracy_score(y_test,y_pred)

y_train_pred = clf1.predict(X_train)
y_test_pred = clf1.predict(X_test)

confusion_matrix(y_train, y_train_pred)

confusion_matrix(y_test, y_test_pred)

print(classification_report(y_test, y_test_pred))

#2. Super vector machine (SVM)algorithm.
x_data = lim_cases_state_df.drop(['date', 'state'],axis = 1)
x_data

X=x_data
y=states

#splitting dataset into 20% / 80% 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# SVM algorithm

clf = svm.SVC()


clf1=clf.fit(X,y)
y_pred = clf1.fit(X_train, y_train).predict(X_test)

accuracy_score(y_test,y_pred)

y_train_pred = clf1.predict(X_train)
y_test_pred = clf1.predict(X_test)

confusion_matrix(y_train, y_train_pred)

confusion_matrix(y_test, y_test_pred)

print(classification_report(y_test, y_test_pred))

# 3. Decision Tree model
x_data = lim_cases_state_df.drop(['date', 'state'],axis = 1)
x_data

X=x_data

states = lim_cases_state_df['state']
states
y=states

#splitting dataset into 20% / 80% 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Decision Tree Classifier Algorithm

clf = DecisionTreeClassifier()

cross_val_score(clf,X,y)


clf.fit(X_train,y_train)

clf1=clf.fit(X,y)
y_pred = clf1.fit(X_train, y_train).predict(X_test)

accuracy_score(y_test,y_pred)

y_train_pred = clf1.predict(X_train)
y_test_pred = clf1.predict(X_test)

confusion_matrix(y_train, y_train_pred)

confusion_matrix(y_test, y_test_pred)

print(classification_report(y_test, y_test_pred))

# 4. Naive Bayes algorithm
x_data = lim_cases_state_df.drop(['date', 'state'],axis = 1)
x_data

X=x_data
y=states

states = lim_cases_state_df['state']
states

#splitting dataset into 20% / 80% 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Naive bayes algorithm

gnb = GaussianNB()
y_pred = gnb.fit(X_train, y_train).predict(X_test)
clf = svm.SVC()


clf1=clf.fit(X,y)
y_train_pred = clf1.predict(X_train)
y_test_pred = clf1.predict(X_test)

accuracy_score(y_test,y_pred)

confusion_matrix(y_train, y_train_pred)

confusion_matrix(y_test, y_test_pred)

print(classification_report(y_test, y_test_pred))